{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ING Den - final challenge\n",
    "## Neuralna Ekipa\n",
    "\n",
    "In this notebook we will do preliminary analysis of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('./datasets/in_time.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much data did we recieve? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310000, 307)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recieved 310k observation with 307 features each. One feature of course is target binary variable, and the rest are features that are listed in Data_dictionary.xlsx. We built then the function, that splits data into specified categories and transform it into usable form. Then we fix -9999 values into NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_analysis(X : pd.DataFrame):\n",
    "    X = X.copy()\n",
    "    X.set_index(['Customer_id'], inplace=True)\n",
    "    real_variables_columns = pd.read_excel('Data_dictionary.xlsx').iloc[:42, :]\n",
    "    types = {k:[] for k in real_variables_columns['Type'].unique()}\n",
    "    X[X == -9999] = pd.NA\n",
    "    real_variables_columns\n",
    "    for feature in real_variables_columns.iterrows():\n",
    "        # all variables with x on the end just land with 1-12\n",
    "        if feature[1]['Column name*'] == 'Customer_id': continue\n",
    "        if(feature[1]['Column name*'][-1] =='x'):\n",
    "            for lag in range(13):\n",
    "                types[feature[1]['Type']].append((feature[1]['Column name*'][:-1]+str(lag)).replace(' ', '_'))\n",
    "        else:\n",
    "            types[feature[1]['Type']].append(feature[1]['Column name*'].replace(' ', '_'))\n",
    "\n",
    "    # at this time we include only numeric features\n",
    "    return X.drop(['Target'], axis=1), X['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into exogenic and endogenic variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation.data_preparation import transform_data\n",
    "\n",
    "X,y = transform_data(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there any missing target variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many variables are missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "External_credit_card_balance             0.999532\n",
       "External_term_loan_balance               0.999532\n",
       "External_mortgage_balance                0.999532\n",
       "Active_credit_card_lines                 0.880958\n",
       "Active_mortgages                         0.820126\n",
       "utilized_limit_in_revolving_loans_H6     0.197065\n",
       "utilized_limit_in_revolving_loans_H2     0.197065\n",
       "utilized_limit_in_revolving_loans_H3     0.197065\n",
       "utilized_limit_in_revolving_loans_H4     0.197065\n",
       "utilized_limit_in_revolving_loans_H5     0.197065\n",
       "utilized_limit_in_revolving_loans_H8     0.197065\n",
       "utilized_limit_in_revolving_loans_H7     0.197065\n",
       "utilized_limit_in_revolving_loans_H0     0.197065\n",
       "utilized_limit_in_revolving_loans_H9     0.197065\n",
       "utilized_limit_in_revolving_loans_H10    0.197065\n",
       "utilized_limit_in_revolving_loans_H11    0.197065\n",
       "utilized_limit_in_revolving_loans_H1     0.197065\n",
       "limit_in_revolving_loans_H10             0.197065\n",
       "limit_in_revolving_loans_H12             0.197065\n",
       "limit_in_revolving_loans_H11             0.197065\n",
       "limit_in_revolving_loans_H9              0.197065\n",
       "limit_in_revolving_loans_H8              0.197065\n",
       "limit_in_revolving_loans_H7              0.197065\n",
       "limit_in_revolving_loans_H6              0.197065\n",
       "limit_in_revolving_loans_H5              0.197065\n",
       "limit_in_revolving_loans_H4              0.197065\n",
       "limit_in_revolving_loans_H3              0.197065\n",
       "limit_in_revolving_loans_H2              0.197065\n",
       "limit_in_revolving_loans_H1              0.197065\n",
       "limit_in_revolving_loans_H0              0.197065\n",
       "utilized_limit_in_revolving_loans_H12    0.197065\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X.loc[:, (np.mean(X.isna(), axis=0) > 0).values].isna(), axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that 99,9532% of all external data is missing (credit card balance, term loan balance, mortgage balance) we will drop these features.\n",
    "\n",
    "Then we see that also active_credit_lines has missing 88%, so we can create varaible *has_credit_card_lines* but drop this variable.\n",
    "\n",
    "Then we see active_mortgages miss 82% of values, we will do the same as to the previous variable.\n",
    "\n",
    "The two variables (and its' derevatives): limit_in_revolving_loans and utilized_limit_in_revolving_loans miss almost 20%, we will drop those features as it would be difficult to impute them.\n",
    "\n",
    "Features to drop are below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = np.mean(X.loc[:, (np.mean(X.isna(), axis=0) > 0).values].isna(), axis=0).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but first we have to prepare some variables as specified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_analysis(X : pd.DataFrame):\n",
    "    X = X.copy()\n",
    "    X.set_index(['Customer_id'], inplace=True)\n",
    "    real_variables_columns = pd.read_excel('Data_dictionary.xlsx').iloc[:42, :]\n",
    "    types = {k:[] for k in real_variables_columns['Type'].unique()}\n",
    "    X[X == -9999] = pd.NA\n",
    "    real_variables_columns\n",
    "    for feature in real_variables_columns.iterrows():\n",
    "        # all variables with x on the end just land with 1-12\n",
    "        if feature[1]['Column name*'] == 'Customer_id': continue\n",
    "        if(feature[1]['Column name*'][-1] =='x'):\n",
    "            for lag in range(13):\n",
    "                types[feature[1]['Type']].append((feature[1]['Column name*'][:-1]+str(lag)).replace(' ', '_'))\n",
    "        else:\n",
    "            types[feature[1]['Type']].append(feature[1]['Column name*'].replace(' ', '_'))\n",
    "    features_to_drop = (X.loc[:, (np.mean(X.isna(), axis=0) > 0).values].isna()).any().index\n",
    "    types['Created'] = []\n",
    "    \n",
    "    # create features that need missing values\n",
    "    types['Created'].append('hasExternal_credit_card_balance')\n",
    "    types['Created'].append('hasExternal_term_loan_balance')\n",
    "    types['Created'].append('hasExternal_mortgage_balance')\n",
    "    types['Created'].append('hasActive_credit_card_lines')\n",
    "    types['Created'].append('hasActive_mortgages')\n",
    "\n",
    "    X['hasExternal_credit_card_balance'] = ~pd.isna(X['External_credit_card_balance'])\n",
    "    X['hasExternal_term_loan_balance'] = ~pd.isna(X['External_term_loan_balance'])\n",
    "    X['hasExternal_mortgage_balance'] = ~pd.isna(X['External_mortgage_balance'])\n",
    "    X['hasActive_credit_card_lines'] = ~pd.isna(X['Active_credit_card_lines'])\n",
    "    X['hasActive_mortgages'] = ~pd.isna(X['Active_mortgages'])\n",
    "\n",
    "    # here we drop features that are missing, at this point we have \n",
    "    X = X.drop(features_to_drop, axis=1)\n",
    "\n",
    "    \n",
    "    return X.drop(['Target'], axis=1), X['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(transform_data_analysis(train_data)[0].isna().any() >0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310000, 279)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ref_month', 'Customer_id', 'Birth_date', 'No_dependants',\n",
       "       'Time_in_address', 'Time_in_current_job', 'Credit_cards', 'Debit_cards',\n",
       "       'Active_accounts', 'Oldest_account_date',\n",
       "       ...\n",
       "       'out_transactions_amt_H9', 'out_transactions_amt_H8',\n",
       "       'out_transactions_amt_H7', 'out_transactions_amt_H6',\n",
       "       'out_transactions_amt_H5', 'out_transactions_amt_H4',\n",
       "       'out_transactions_amt_H3', 'out_transactions_amt_H2',\n",
       "       'out_transactions_amt_H1', 'out_transactions_amt_H0'],\n",
       "      dtype='object', length=306)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {k:[] for k in real_variables_columns['Type'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_variables_columns\n",
    "for feature in real_variables_columns.iterrows():\n",
    "    # all variables with x on the end just land with 1-12\n",
    "    if(feature[1]['Column name*'][-1] =='x'):\n",
    "        for lag in range(13):\n",
    "            types[feature[1]['Type']].append((feature[1]['Column name*'][:-1]+str(lag)).replace(' ', '_'))\n",
    "    else:\n",
    "        types[feature[1]['Type']].append(feature[1]['Column name*'].replace(' ', '_'))\n",
    "\n",
    "for type in types:\n",
    "    for subtype in types[type]:\n",
    "        if not subtype in X_train.columns:\n",
    "            print(subtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so to summarize, plot below shows how many variables are in each type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.DataFrame({k:len(x) for k,x in types.items()}, index=['no. of features'])\n",
    "ax = df.T.plot.bar()\n",
    "plt.title(\"Number of features in each category\")\n",
    "plt.grid(True)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is 1 variable that contains month, 35 non bound integer variables, 4 date variables with month, 39 variables bounded to 330, 13 binary variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before next step we will drop obviously random (non-discriminatory variables) using Gini Coefficient (to drop obviously non-discriminatory variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will create new variables by hand, and then we will pass all variables via GiniSelector that will remove purely random (non discriminatory) features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_features(X):\n",
    "    # Implicit assumption in place that dataset has the same structure as in the in_time.csv, out_of_time.csv files\n",
    "    print(X['Birth_date'][:-5])\n",
    "\n",
    "create_new_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preparation.additional_transformers import GiniSelector\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "\n",
    "\n",
    "gs = GiniSelector(0.01)\n",
    "column_transformer = make_column_transformer(\n",
    "    (gs, types['Float'] + types['Integer'] + types['Integer (0 or 1)'] + types['Integer (0-330)']),\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "data_trimmed = column_transformer.fit_transform(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_after_gini = pd.DataFrame(data_trimmed, columns=[x.split('__')[1] for x in column_transformer.get_feature_names_out()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
